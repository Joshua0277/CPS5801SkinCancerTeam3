{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0YYfEi21WKcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project: Skin Cancer Classification\n",
        "# Team Members:\n",
        "#  Chin-Chien Lin: Data loading, preprocessing, ResNet18 training\n",
        "#  Christian Rasmussen: EfficientNet training, Random Forest implementation, metrics comparison\n",
        "\n",
        "#  Both: Final integration, formatting, result interpretation"
      ],
      "metadata": {
        "id": "4N3nlOqyUQR-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJmV7OhlVv_E",
        "outputId": "9830b167-c98f-40ca-e640-d5c5a472d57f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/skin-cancer-malignant-vs-benign\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"fanconic/skin-cancer-malignant-vs-benign\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Root path:\", path)\n",
        "print(\"Subfolders:\", os.listdir(path))\n",
        "train_path = os.path.join(path, \"train\")\n",
        "test_path = os.path.join(path, \"test\")\n",
        "print(\"Inside train/:\", os.listdir(train_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrkyYM_wosGg",
        "outputId": "0e68a648-6931-4f86-9675-a1bd526f9ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root path: /kaggle/input/skin-cancer-malignant-vs-benign\n",
            "Subfolders: ['data', 'test', 'train']\n",
            "Inside train/: ['benign', 'malignant']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# set path\n",
        "data_dir = path\n",
        "\n",
        "# Define transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ColorJitter(brightness=0.2),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load full dataset using ImageFolder\n",
        "train_path = os.path.join(path, \"train\")\n",
        "full_dataset = datasets.ImageFolder(train_path, transform=train_transforms)\n",
        "test_dataset = datasets.ImageFolder(test_path, transform=val_test_transforms)\n",
        "\n",
        "# Split into train (80%), val (20%)\n",
        "total_len = len(full_dataset)\n",
        "train_len = int(0.8 * total_len)\n",
        "val_len =  total_len - train_len\n",
        "test_len = total_len - train_len - val_len\n",
        "\n",
        "train_set, val_set = random_split(full_dataset, [train_len, val_len])\n",
        "\n",
        "# Assign validation and test sets the correct transform\n",
        "val_set.dataset.transform = val_test_transforms\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "o0G8Mxe6WvwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# load ResNet18 and use ImageNet's pretrained weights\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# replace fully connected layer in the end，to be a value\n",
        "model.fc = nn.Linear(model.fc.in_features, 1)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function & Optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtahVwwEXMMK",
        "outputId": "ffe54d83-05b1-470e-88b7-b69d4bb55a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 175MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet-18 Training"
      ],
      "metadata": {
        "id": "QWcjlebCWjxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=5):\n",
        "    best_val_acc = 0\n",
        "    best_val_acc = 0\n",
        "    patience_counter = 0\n",
        "    early_stop_patience = 7\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Training phase\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
        "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)  # Reshape to (B, 1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_acc = correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "                outputs = model(images)\n",
        "                preds = torch.sigmoid(outputs) > 0.5\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), \"best_resnet18.pth\")\n",
        "            print(\" Best model saved\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= early_stop_patience:\n",
        "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    print(f\" Training complete. Best validation accuracy: {best_val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "hMIHfTWsXutL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yG9mfLcZ8Mt",
        "outputId": "ea8b878e-cfe1-44f8-ddb6-5428be49fa41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/25 - Training: 100%|██████████| 66/66 [00:23<00:00,  2.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25] - Loss: 0.3528, Train Acc: 0.8246, Val Acc: 0.8788\n",
            " Best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/25] - Loss: 0.1249, Train Acc: 0.9550, Val Acc: 0.8807\n",
            " Best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/25] - Loss: 0.0631, Train Acc: 0.9777, Val Acc: 0.8902\n",
            " Best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/25] - Loss: 0.0193, Train Acc: 0.9976, Val Acc: 0.8977\n",
            " Best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/25] - Loss: 0.0099, Train Acc: 0.9986, Val Acc: 0.9015\n",
            " Best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/25] - Loss: 0.0105, Train Acc: 0.9976, Val Acc: 0.9072\n",
            " Best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/25] - Loss: 0.0070, Train Acc: 0.9991, Val Acc: 0.8996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/25] - Loss: 0.0025, Train Acc: 1.0000, Val Acc: 0.9034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/25] - Loss: 0.0018, Train Acc: 1.0000, Val Acc: 0.9053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/25] - Loss: 0.0019, Train Acc: 1.0000, Val Acc: 0.9072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/25] - Loss: 0.0029, Train Acc: 1.0000, Val Acc: 0.9167\n",
            " Best model saved\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/25] - Loss: 0.0021, Train Acc: 1.0000, Val Acc: 0.9110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/25] - Loss: 0.0025, Train Acc: 1.0000, Val Acc: 0.8939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/25] - Loss: 0.0019, Train Acc: 1.0000, Val Acc: 0.9053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/25] - Loss: 0.0008, Train Acc: 1.0000, Val Acc: 0.9110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/25] - Loss: 0.0083, Train Acc: 0.9967, Val Acc: 0.8807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/25] - Loss: 0.2110, Train Acc: 0.9284, Val Acc: 0.8561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/25 - Training: 100%|██████████| 66/66 [00:11<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/25] - Loss: 0.1003, Train Acc: 0.9621, Val Acc: 0.9034\n",
            "Early stopping triggered at epoch 18\n",
            " Training complete. Best validation accuracy: 0.9167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation & Random Forest implementation"
      ],
      "metadata": {
        "id": "lE0DqgUqUric"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import torch\n",
        "# Load best ResNet18 model from training\n",
        "model.load_state_dict(torch.load(\"best_resnet18.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# Inference on test set for ResNet18\n",
        "y_true, y_pred, y_probs = [], [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        logits = model(imgs).squeeze(1)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).long().cpu().numpy()\n",
        "\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(labels.numpy())\n",
        "        y_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "# Convert to numpy arrays\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "y_probs = np.array(y_probs)\n",
        "\n",
        "# Display evaluation metrics\n",
        "print(\"\\n Test Set Evaluation (ResNet18):\")\n",
        "print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
        "print(\"Precision:\", precision_score(y_true, y_pred))\n",
        "print(\"Recall   :\", recall_score(y_true, y_pred))\n",
        "print(\"F1 Score :\", f1_score(y_true, y_pred))\n",
        "print(\"AUC      :\", roc_auc_score(y_true, y_probs))\n",
        "\n",
        "# Confusion matrix and classification report\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\nConfusion Matrix (ResNet18):\\n\", cm)\n",
        "print(\"\\nClassification Report (ResNet18):\\n\",\n",
        "      classification_report(y_true, y_pred, target_names=[\"Benign\",\"Malignant\"]))\n",
        "\n",
        "# -------------------- Random Forest Baseline --------------------\n",
        "\n",
        "# Function to flatten images for traditional ML input\n",
        "def flatten_loader(dl):\n",
        "    Xs, Ys = [], []\n",
        "    for imgs, labels in dl:\n",
        "        flat = imgs.view(imgs.size(0), -1).cpu().numpy()\n",
        "        Xs.append(flat)\n",
        "        Ys.append(labels.numpy())\n",
        "    return np.vstack(Xs), np.concatenate(Ys)\n",
        "\n",
        "# Flatten training and test sets\n",
        "X_train, y_train = flatten_loader(train_loader)\n",
        "X_test,  y_test  = flatten_loader(test_loader)\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Random Forest metrics\n",
        "y_probs_rf = rf.predict_proba(X_test)[:, 1]\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "print(\"\\n Random Forest Evaluation:\")\n",
        "print(\"Accuracy :\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
        "print(\"Recall   :\", recall_score(y_test, y_pred_rf))\n",
        "print(\"F1 Score :\", f1_score(y_test, y_pred_rf))\n",
        "print(\"AUC      :\", roc_auc_score(y_test, y_probs_rf))\n",
        "\n",
        "print(\"\\nConfusion Matrix (Random Forest):\\n\", cm_rf)\n",
        "print(\"\\nClassification Report (Random Forest):\\n\",\n",
        "      classification_report(y_test, y_pred_rf, target_names=[\"Benign\",\"Malignant\"]))\n"
      ],
      "metadata": {
        "id": "9NaNVp_UeSYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6da644c-3de4-46ad-8a65-96050da7b9fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Test Set Evaluation (ResNet18):\n",
            "Accuracy : 0.8848484848484849\n",
            "Precision: 0.85\n",
            "Recall   : 0.9066666666666666\n",
            "F1 Score : 0.8774193548387097\n",
            "AUC      : 0.9581944444444445\n",
            "\n",
            "Confusion Matrix (ResNet18):\n",
            " [[312  48]\n",
            " [ 28 272]]\n",
            "\n",
            "Classification Report (ResNet18):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.92      0.87      0.89       360\n",
            "   Malignant       0.85      0.91      0.88       300\n",
            "\n",
            "    accuracy                           0.88       660\n",
            "   macro avg       0.88      0.89      0.88       660\n",
            "weighted avg       0.89      0.88      0.89       660\n",
            "\n",
            "\n",
            " Random Forest Evaluation:\n",
            "Accuracy : 0.8348484848484848\n",
            "Precision: 0.7800586510263929\n",
            "Recall   : 0.8866666666666667\n",
            "F1 Score : 0.8299531981279251\n",
            "AUC      : 0.904425925925926\n",
            "\n",
            "Confusion Matrix (Random Forest):\n",
            " [[285  75]\n",
            " [ 34 266]]\n",
            "\n",
            "Classification Report (Random Forest):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.89      0.79      0.84       360\n",
            "   Malignant       0.78      0.89      0.83       300\n",
            "\n",
            "    accuracy                           0.83       660\n",
            "   macro avg       0.84      0.84      0.83       660\n",
            "weighted avg       0.84      0.83      0.84       660\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EfficientNet-B0"
      ],
      "metadata": {
        "id": "LIGdYOW_WXQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qXM7J7L6LWfr",
        "outputId": "d64ab170-1b9f-4001-9d03-93b0ea7e0b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from efficientnet_pytorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->efficientnet_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->efficientnet_pytorch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m738.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16426 sha256=47829aad806b7345019d22680669b9daae97bcfb8ee973380962cfd20fc67ef5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/6f/9b/231a832f811ab6ebb1b32455b177ffc6b8b1cd8de19de70c09\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet_pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed efficientnet_pytorch-0.7.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "GmACrlpnN5Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "# Load a pre-trained EfficientNet-B0 model\n",
        "model = EfficientNet.from_pretrained('efficientnet-b0')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB0k6Gb1MPfB",
        "outputId": "f32e2f94-00d9-4b0d-bbf6-64ef69cf649f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n",
            "100%|██████████| 20.4M/20.4M [00:00<00:00, 190MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# set path\n",
        "data_dir = path\n",
        "\n",
        "# Define transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ColorJitter(brightness=0.2),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load full dataset using ImageFolder\n",
        "train_path = os.path.join(path, \"train\")\n",
        "full_dataset = datasets.ImageFolder(train_path, transform=train_transforms)\n",
        "test_dataset = datasets.ImageFolder(test_path, transform=val_test_transforms)\n",
        "\n",
        "# Split into train (70%), val (15%), test (15%)\n",
        "total_len = len(full_dataset)\n",
        "train_len = int(0.8 * total_len)\n",
        "val_len =  total_len - train_len\n",
        "test_len = total_len - train_len - val_len\n",
        "\n",
        "train_set, val_set = random_split(full_dataset, [train_len, val_len])\n",
        "\n",
        "# Assign validation and test sets the correct transform\n",
        "val_set.dataset.transform = val_test_transforms\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "YVDP9caIQLBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load EfficientNet-B0 with ImageNet pre-trained weights\n",
        "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "\n",
        "# Replace the fully connected layer for binary classification (output = 1)\n",
        "model._fc = nn.Linear(model._fc.in_features, 1)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function & Optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y53ShQm3UV5K",
        "outputId": "cd723b4d-5cb7-49f4-fd7c-793920fdf6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EfficientNet-B0 Training & Evaluation"
      ],
      "metadata": {
        "id": "QrxhnVFsXgqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=5):\n",
        "    best_val_acc = 0\n",
        "    patience_counter = 0\n",
        "    early_stop_patience = 7\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Training phase\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device).float().unsqueeze(1)  # Reshape to (B, 1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_acc = correct / total\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device).float().unsqueeze(1)\n",
        "                outputs = model(images)\n",
        "                preds = torch.sigmoid(outputs) > 0.5\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), \"best_efficientnet_b0.pth\")\n",
        "            print(\" Best model saved\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= early_stop_patience:\n",
        "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    print(f\"Training complete. Best validation accuracy: {best_val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "WA3nW8wgVPoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SxFZAPmVmhv",
        "outputId": "4309ed8b-e1f7-48f7-807b-7df717abfcf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/25 - Training: 100%|██████████| 66/66 [00:21<00:00,  3.11it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/25] - Loss: 0.4756, Train Acc: 0.8203, Val Acc: 0.6818\n",
            " Best model saved\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/25 - Training: 100%|██████████| 66/66 [00:19<00:00,  3.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/25] - Loss: 0.2787, Train Acc: 0.8919, Val Acc: 0.7822\n",
            " Best model saved\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/25 - Training: 100%|██████████| 66/66 [00:19<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/25] - Loss: 0.2023, Train Acc: 0.9232, Val Acc: 0.8201\n",
            " Best model saved\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/25 - Training: 100%|██████████| 66/66 [00:19<00:00,  3.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/25] - Loss: 0.1481, Train Acc: 0.9469, Val Acc: 0.8731\n",
            " Best model saved\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/25 - Training: 100%|██████████| 66/66 [00:19<00:00,  3.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/25] - Loss: 0.0901, Train Acc: 0.9725, Val Acc: 0.8788\n",
            " Best model saved\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/25 - Training: 100%|██████████| 66/66 [00:19<00:00,  3.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/25] - Loss: 0.0614, Train Acc: 0.9862, Val Acc: 0.8769\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/25 - Training: 100%|██████████| 66/66 [00:19<00:00,  3.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/25] - Loss: 0.0382, Train Acc: 0.9915, Val Acc: 0.8883\n",
            " Best model saved\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/25 - Training: 100%|██████████| 66/66 [00:18<00:00,  3.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/25] - Loss: 0.0397, Train Acc: 0.9877, Val Acc: 0.8864\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/25 - Training: 100%|██████████| 66/66 [00:18<00:00,  3.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/25] - Loss: 0.0210, Train Acc: 0.9948, Val Acc: 0.8902\n",
            " Best model saved\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/25 - Training: 100%|██████████| 66/66 [00:19<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/25] - Loss: 0.0298, Train Acc: 0.9915, Val Acc: 0.8788\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/25 - Training: 100%|██████████| 66/66 [00:19<00:00,  3.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/25] - Loss: 0.0231, Train Acc: 0.9938, Val Acc: 0.8788\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/25 - Training: 100%|██████████| 66/66 [00:19<00:00,  3.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/25] - Loss: 0.0185, Train Acc: 0.9943, Val Acc: 0.8731\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/25 - Training: 100%|██████████| 66/66 [00:18<00:00,  3.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/25] - Loss: 0.0166, Train Acc: 0.9967, Val Acc: 0.8712\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/25 - Training: 100%|██████████| 66/66 [00:19<00:00,  3.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/25] - Loss: 0.0132, Train Acc: 0.9967, Val Acc: 0.8845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/25 - Training: 100%|██████████| 66/66 [00:19<00:00,  3.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/25] - Loss: 0.0115, Train Acc: 0.9976, Val Acc: 0.8845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/25 - Training: 100%|██████████| 66/66 [00:18<00:00,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/25] - Loss: 0.0110, Train Acc: 0.9976, Val Acc: 0.8902\n",
            "Early stopping triggered at epoch 16\n",
            "Training complete. Best validation accuracy: 0.8902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load best EfficientNet-B0 model from training\n",
        "model.load_state_dict(torch.load(\"best_efficientnet_b0.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# Inference on test set for EfficientNet-B0\n",
        "y_true, y_pred, y_probs = [], [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        logits = model(imgs).squeeze(1)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).long().cpu().numpy()\n",
        "\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(labels.numpy())\n",
        "        y_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "# Convert to numpy arrays\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "y_probs = np.array(y_probs)\n",
        "\n",
        "# Display evaluation metrics\n",
        "print(\"\\nTest Set Evaluation (EfficientNet-B0):\")\n",
        "print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
        "print(\"Precision:\", precision_score(y_true, y_pred))\n",
        "print(\"Recall   :\", recall_score(y_true, y_pred))\n",
        "print(\"F1 Score :\", f1_score(y_true, y_pred))\n",
        "print(\"AUC      :\", roc_auc_score(y_true, y_probs))\n",
        "\n",
        "# Confusion matrix and classification report\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\nConfusion Matrix (EfficientNet-B0):\\n\", cm)\n",
        "print(\"\\nClassification Report (EfficientNet-B0):\\n\",\n",
        "      classification_report(y_true, y_pred, target_names=[\"Benign\", \"Malignant\"]))\n",
        "\n",
        "# -------------------- Random Forest Baseline --------------------\n",
        "\n",
        "# Function to flatten images for traditional ML input\n",
        "def flatten_loader(dl):\n",
        "    Xs, Ys = [], []\n",
        "    for imgs, labels in dl:\n",
        "        flat = imgs.view(imgs.size(0), -1).cpu().numpy()\n",
        "        Xs.append(flat)\n",
        "        Ys.append(labels.numpy())\n",
        "    return np.vstack(Xs), np.concatenate(Ys)\n",
        "\n",
        "# Flatten training and test sets\n",
        "X_train, y_train = flatten_loader(train_loader)\n",
        "X_test,  y_test  = flatten_loader(test_loader)\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Random Forest metrics\n",
        "y_probs_rf = rf.predict_proba(X_test)[:, 1]\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "print(\"\\nRandom Forest Evaluation:\")\n",
        "print(\"Accuracy :\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
        "print(\"Recall   :\", recall_score(y_test, y_pred_rf))\n",
        "print(\"F1 Score :\", f1_score(y_test, y_pred_rf))\n",
        "print(\"AUC      :\", roc_auc_score(y_test, y_probs_rf))\n",
        "\n",
        "print(\"\\nConfusion Matrix (Random Forest):\\n\", cm_rf)\n",
        "print(\"\\nClassification Report (Random Forest):\\n\",\n",
        "      classification_report(y_test, y_pred_rf, target_names=[\"Benign\", \"Malignant\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9illLjxkWpxG",
        "outputId": "1ca002be-ab5f-4974-fc35-48f79fc09d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Set Evaluation (EfficientNet-B0):\n",
            "Accuracy : 0.9015151515151515\n",
            "Precision: 0.8983050847457628\n",
            "Recall   : 0.8833333333333333\n",
            "F1 Score : 0.8907563025210085\n",
            "AUC      : 0.9528888888888889\n",
            "\n",
            "Confusion Matrix (EfficientNet-B0):\n",
            " [[330  30]\n",
            " [ 35 265]]\n",
            "\n",
            "Classification Report (EfficientNet-B0):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.90      0.92      0.91       360\n",
            "   Malignant       0.90      0.88      0.89       300\n",
            "\n",
            "    accuracy                           0.90       660\n",
            "   macro avg       0.90      0.90      0.90       660\n",
            "weighted avg       0.90      0.90      0.90       660\n",
            "\n",
            "\n",
            "Random Forest Evaluation:\n",
            "Accuracy : 0.8333333333333334\n",
            "Precision: 0.7810650887573964\n",
            "Recall   : 0.88\n",
            "F1 Score : 0.8275862068965517\n",
            "AUC      : 0.9015324074074074\n",
            "\n",
            "Confusion Matrix (Random Forest):\n",
            " [[286  74]\n",
            " [ 36 264]]\n",
            "\n",
            "Classification Report (Random Forest):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.89      0.79      0.84       360\n",
            "   Malignant       0.78      0.88      0.83       300\n",
            "\n",
            "    accuracy                           0.83       660\n",
            "   macro avg       0.83      0.84      0.83       660\n",
            "weighted avg       0.84      0.83      0.83       660\n",
            "\n"
          ]
        }
      ]
    }
  ]
}